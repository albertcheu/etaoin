-Ideally, this project will be able to construct representations of scenes of polygons AND abstract shared properties between different scenes (pseudo-Bongard)

-Modules
  -Color recognition (directory 'color'; run trainingWindow & testingWindow)
    -Generate random RGB values
    -Show color
    -Pair triple with one or more of these:
      -Red, orange, yellow, green, blue, violet, pink, cyan
      -Black, white, gray, brown, tan
    -Partition 0-255 into blocks
    -Build decision tree

  -Space definitions (space.py)
    -left, right, top, bottom, corner, upper, lower, center, middle

  -Image generation (makeScene.py, sceneInput; makes scene.png)
    -The file sceneInput tells what the scene (initially) looks like
    -It has format:
      -Background color
      -number of shapes
      -Shape color
      -number of sides
      -Region of scene (0 is top left, 1 is top-center, ...8 is bottom right)
    -makeScene uses polygon.py to make the polygons, PIL to make the png
    -In the future, the user should be able to m 

  -Querying (makeScene, interface, handlers, filters, utility, constants)
    -After creating the scene, makeScene presents a terminal interface
    -The program parses English sentences and provides appropriate responses
    -constants.py & utility.py hold handy data elements and functions

  -TO DO
    -Instead of makeScene providing the interface, have a standalone .py
      -This means representation is derived from .png, not from sceneInput
      -analyzeScene.py is buggy :(

    -Allow for natural language movement of the polygons
      -Would have to be a part of makeScene

    -Generate natural language assertions about (the rep. of) the scene
      -For simplicity, only positive assertions (no use of 'no' or 'not')
      -In theory, if a true assertion is shared among multiple scenes, we have found a shared property
      -How it's done:
        -simplest - check the background color
	-build the set of polygon colors
	-build the set of polygon types
	-build the set of locations